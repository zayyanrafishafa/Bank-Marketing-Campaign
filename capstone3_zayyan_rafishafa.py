# -*- coding: utf-8 -*-
"""Capstone3_Zayyan Rafishafa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15xrMSAxKL1TyarKRss1z3vLObBqMhyVs

Zayyan Rafishafa Kabullah Nugraha - Capstone 3

**Bank Marketing Campaign**
"""

!pip install category_encoders

# Install missing package
!pip install category_encoders

# Then import everything
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Data Preparation
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder, StandardScaler
from category_encoders import BinaryEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier

# Evaluation
from sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score, precision_score

"""#Introduction

##Background

The public now use a wider range of financial products, with term deposits being among the most familiar. Customers place a certain amount of money in a bank or financial institution, which can only be withdrawn after a certain period. In return, the customer receives a fixed interest rate based on the deposited amount.

However, as financial corporations such as banks must remain competitive to retain and attract customers. One key strategy to gain new customers is through targeted marketing campaigns.

# Business Understanding

If the primary goal of the campaign is to capture as many potential deposits or customers as possible, the model should prioritize recall during selection, even at the cost of lower precision, accepting more false positives and preparing the marketing team for increased outreach efforts with the understanding that some contacted leads will not convert. However, if the outreach budget is limited, it is better to balance recall and precision, such as by using the F1-score, to ensure a more efficient use of resources.

##Business Problem

Despite offering attractive term deposit products, the bank faces challenges in acquiring new deposit customers in a competitive financial market. By analyzing customer profile data (e.g., age, job, balance, housing, loan) and past marketing interactions (e.g., contact type, month, campaign frequency, previous outcomes), this project aims to develop a predictive model that can:

Classify whether a customer is likely to subscribe to a term deposit (deposit = yes/no)
Uncover insights into which customer attributes and campaign strategies are most associated with success
Support targeted and cost-efficient marketing efforts

## Problem Statement

How can we optimize this marketing campaign to attract customers?

# Data Understanding

Data Cateogory Information

| Category | Data Type   | Description                                                                  |
| --------- | ----------- | ---------------------------------------------------------------------------- |
| age       | Integer     | Age of the customer                                                          |
| job       | Categorical | Type of job/occupation of the customer                                       |
| balance   | Integer     | Customer's account balance                                                   |
| housing   | Categorical | Whether the customer has a housing loan                                      |
| loan      | Categorical | Whether the customer has a personal loan                                     |
| contact   | Categorical | Type of last contact communication                                           |
| month     | Categorical | Month of the last contact                                                    |
| campaign  | Integer     | Number of contacts made during this marketing campaign                       |
| pdays     | Integer     | Number of days since the customer was last contacted (-1 if never contacted) |
| poutcome  | Categorical | Outcome of the previous marketing campaign                                   |
| deposit   | Categorical | Target: whether the customer subscribed to a term deposit                    |
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('/content/data_bank_marketing_campaign.csv')

# Standardize column names
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

# View basic info
df.shape, df.columns.tolist()

"""This shows the dataset's categories

## Display data's general structure
"""

print("Dataset shape:", df.shape)
print("\nColumns:\n", df.columns.tolist())

# Data types and non-null values
df.info()

# Preview data
df.head()

"""## Statistical Summary"""

# Numerical summary
df.describe()

# Categorical summary
df.describe(include='object')

"""## Check for missing values"""

# Null values
print("\nMissing values:")
print(df.isnull().sum())

# 'unknown' entries (common in this dataset)
print("\n'unknown' counts per column:")
print(df.apply(lambda x: (x == 'unknown').sum() if x.dtype == 'object' else 0))

"""## Categorical Feature Distributions"""

categorical_cols = df.select_dtypes(include='object').columns.tolist()

for col in categorical_cols:
    plt.figure(figsize=(8, 3))
    sns.countplot(y=col, data=df, order=df[col].value_counts().index)
    plt.title(f'Distribution of {col}')
    plt.tight_layout()
    plt.show()

"""- Many categorical variables are imbalanced
- Features like month and contact type may reflect marketing operations rather than customer behavior (risk of data leakage).
- Rare categories (e.g., “default=yes”, “student”) should be treated carefully → may need grouping or dropped if not informative.

## Distribution Testing - Pearson Correlation Test
"""

import pandas as pd
from scipy.stats import normaltest

# Load your dataset
df = pd.read_csv("data_bank_marketing_campaign.csv")

# Select numeric columns
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
print("Numeric columns:", numeric_cols)

alpha = 0.05  # significance level

results = []
for col in numeric_cols:
    stat, p = normaltest(df[col])
    results.append({
        'Column': col,
        'Statistic': stat,
        'p-value': p,
        'Normal?': 'Likely normal' if p > alpha else 'Not normal'
    })

results_df = pd.DataFrame(results)
print(results_df)

import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats

for col in numeric_cols:
    plt.figure(figsize=(12,4))

    plt.subplot(1,2,1)
    sns.histplot(df[col], kde=True)
    plt.title(f'Histogram of {col}')

    plt.subplot(1,2,2)
    stats.probplot(df[col], dist="norm", plot=plt)
    plt.title(f'Q-Q Plot of {col}')

    plt.tight_layout()
    plt.show()

"""None of the continuous features follow a normal distribution.
Strong skewness and outliers present (especially in campaign, pdays, balance).
For modeling:
- Tree-based models can handle skewness well.
- Outliers may distort mean/variance, so careful preprocessing is needed.

## Numerical Feature Distributions
"""

numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

df[numerical_cols].hist(figsize=(12, 10), bins=30)
plt.suptitle("Numerical Feature Distributions", fontsize=16)
plt.tight_layout()
plt.show()

"""**Analysis**

- None of the numerical variables are normally distributed.
- Skewness and outliers are present, especially in balance, campaign, and pdays.

Correlation Matrix
"""

corr = df[numerical_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Correlation Between Numerical Features")
plt.show()

"""**Analysis**
- Correlations among numerical features are very weak (close to 0).
- No strong linear relationships observed, reducing the risk of multicollinearity.

**Data Classification**

*   Target (deposit): "yes" or "no"
*   Type: Categorical, specifically binary
*   Prediction goal: Will the customer say "yes" or "no" to the deposit offer?
*   Appropriate ML type: Classification

Categorical vs Target
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load dataset — change filename to match the uploaded CSV
df = pd.read_csv('/content/data_bank_marketing_campaign.csv')

# Standardize column names
df.columns = (
    df.columns.str.strip()
              .str.lower()
              .str.replace(' ', '_')
)

print("Columns:", df.columns.tolist()[:20], " ...")  # quick peek

# Detect target column
possible_targets = ['deposit']  # in the raw file it's likely 'deposit', not 'deposit_yes'
target = next((t for t in possible_targets if t in df.columns), None)
if target is None:
    raise ValueError(f"Couldn't find target column among {possible_targets}. Available columns: {df.columns.tolist()}")

print("Using target:", target)

# Derive categorical columns from *current* df (exclude target)
categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
categorical_cols = [c for c in categorical_cols if c != target]

print("Categorical cols:", categorical_cols)

# Safety: ensure every column exists
categorical_cols = [c for c in categorical_cols if c in df.columns]

# Plot stacked bar: category vs target proportion
for col in categorical_cols:
    if df[col].nunique(dropna=False) > 1:  # avoid constant columns
        ct = pd.crosstab(df[col], df[target], normalize='index')
        ct.plot(kind='bar', stacked=True, figsize=(8, 4))
        plt.title(f'{col} vs {target}')
        plt.ylabel('Proportion')
        plt.tight_layout()
        plt.show()

"""**Goal of the Model:**

- Predict whether a client will subscribe (class membership), not how much they will subscribe (a quantity).

**Evaluation Metrics:**
- Classification metrics like accuracy, precision, recall, F1, ROC-AUC are suitable. Regression metrics like MSE, RMSE are not applicable here.

**Visual Evidence :**
- All plots show target categories split into two groups (yes/no), confirming a binary classification problem.

# Data Cleaning

Load the data
"""

import pandas as pd
import numpy as np

# Load the CSV
df = pd.read_csv('/content/data_bank_marketing_campaign.csv')

# View basic structure
df.info()
df.head()

"""Clean Columns"""

# Total missing values per column
df.isnull().sum()

# Percentage of missing values
df.isnull().mean() * 100

"""Check Missing Values"""

df.isnull().sum()        # Total missing per column
df.isnull().mean() * 100 # Percentage of missing

"""Drop Duplicates"""

df.drop_duplicates(inplace=True)

"""Categorize Columns"""

categorical_cols = df.select_dtypes(include='object').columns.tolist()
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

"""Fix Inconsistent Entries"""

# Lowercasing and removing spaces
for col in categorical_cols:
    df[col] = df[col].str.lower().str.strip()

"""Handle Missing or Unknown Values"""

df.replace("unknown", np.nan, inplace=True)

# Impute categorical values with mode
for col in categorical_cols:
    if df[col].isnull().sum() > 0:
        df[col].fillna(df[col].mode()[0], inplace=True)

"""Check for Outliers"""

Q1 = df[numerical_cols].quantile(0.25)
Q3 = df[numerical_cols].quantile(0.75)
IQR = Q3 - Q1

# Filter out outliers
df = df[~((df[numerical_cols] < (Q1 - 1.5 * IQR)) | (df[numerical_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]

"""Encode Categorical Features"""

df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

"""Saves Cleaned Data"""

df.to_csv("data_bank_marketing_cleaned.csv", index=False)

"""In the following process, the **cleaned** data is renamed into data_bank_marketing.csv again

# EDA (Exploratory Data Analysis)
"""

# Summary of Statistics

"""## Why do we need machine learning?

Machine Learning is important because it can uncover complex patterns that manual formulas or simple logic cannot solve.

It processes many features at once to reveal hidden relationships, works efficiently with large and unique data sets, and enables real-time predictions or decisions. It also captures interactions between variables, adapts to new data through retraining, and goes beyond Exploratory Data Analysis by analyzing the combined impact of all features for deeper and more accurate insights.

## When do we don't need machine learning?

Machine Learning is not always the right solution, especially when the rules are already clear, such as:

*   Calculating discounts
*   Checking empty email fields

They are often solved more efficiently using basic programming logic like if statements, loops, or formulas. Without historical data, Machine Learning cannot function effectively, and in cases where full transparency is required, complex models can be difficult to explain. If the rules are fixed, a rule-based approach is often more efficient, and ML does not always outperform simpler statistical methods. For small-scale problems, the time and cost of developing and maintaining an ML model may outweigh the benefits, making traditional approaches more practical.

## Encoding Categorical Features
"""

from sklearn.preprocessing import OneHotEncoder

# One-hot encoding for categorical variables
df_encoded = pd.get_dummies(df, drop_first=True)

print(df_encoded.head())

"""## Scaling Numeric Features"""

from sklearn.preprocessing import StandardScaler

# Select numeric columns
numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns

scaler = StandardScaler()
df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])

print(df_encoded.head())

"""## Defining Features"""

import re

# 1) Try common binary targets exactly
candidates_exact = ["y_yes", "deposit_yes", "subscribed_yes", "subscription_yes",
                    "y", "deposit", "subscribed", "subscription", "target"]

target_col = None
for c in candidates_exact:
    if c in df_encoded.columns:
        target_col = c
        break

# 2) If not found, try regex pattern like <name>_(yes|1|true)
if target_col is None:
    pattern = re.compile(r"^(y|deposit|subscribed|subscription|target)_(yes|1|true)$", re.I)
    for c in df_encoded.columns:
        if pattern.match(c):
            target_col = c
            break

# 3) As a last resort, if there are exactly two one-hot columns for the target (e.g., y_no & y_yes),
#    pick the one that looks like the positive class
if target_col is None:
    pairs = []
    for base in ["y", "deposit", "subscribed", "subscription", "target"]:
        cols = [c for c in df_encoded.columns if c.lower().startswith(base.lower() + "_")]
        if len(cols) == 2 and all(v in "|".join(cols).lower() for v in ["yes", "no"]):
            # Prefer the “yes”
            target_col = [c for c in cols if c.lower().endswith("_yes")][0]
            break

if target_col is None:
    raise ValueError(f"Could not find a target column in df_encoded. Columns available: {list(df_encoded.columns)[:30]} ...")

print(f"Using target column: {target_col}")

y = df_encoded[target_col]
X = df_encoded.drop(columns=[target_col])

"""**Analysis Result**
- **Detected Target Column:** `deposit_yes`
- **Target Type:** Binary classification (Yes/No

### Why Focus on Recall as measurement metrics?

- **Recall is most important** because:
  - Missing a real subscriber (False Negative) = lost revenue opportunity.
  - False Positive (predicting subscriber when they are not) only wastes some marketing effort.

- **Other metrics:**
  - **Precision:** less critical, since contacting a few uninterested customers is acceptable.
  - **F1-Score:** balances precision & recall, but recall is the higher business priority.
  - **ROC-AUC:** useful for comparing models, not directly tied to minimizing missed customers.
  - **PR Curve:** good for visualization in imbalanced data, but still recall remains key.

# Data Splitting
"""

import pandas as pd

# Load dataset
df = pd.read_csv("data_bank_marketing_campaign.csv")

# Quick view
print(df.shape)
df.head()

import pandas as pd
from sklearn.model_selection import train_test_split

# 1. Load dataset
df = pd.read_csv("data_bank_marketing_campaign.csv")

# 2. Define features (X) and target (y)
target = "deposit"
X = df.drop(columns=[target])
y = df[target]

# 3. Split into train+val and test
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y,
    test_size=0.15,
    random_state=42,
    stratify=y
)

# 4. Split train and validation
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=0.1765,   # ~15% of total for validation
    random_state=42,
    stratify=y_train_val
)

# 5. Check shapes
print(f"Train: {len(X_train)} rows")
print(f"Validation: {len(X_val)} rows")
print(f"Test: {len(X_test)} rows")

"""# Data Preparation"""

# Standardize column names (very common in your Module 3 notebooks)
df.columns = (
    df.columns.str.strip()
              .str.lower()
              .str.replace(' ', '_')
              .str.replace('.', '', regex=False)
)

df.shape, df.head()
df.info()         # check dtypes & missing
df.describe()     # numeric summary (optional)
df['deposit'].value_counts(dropna=False)  # class balance

"""Train / Val / Test split (with stratification)"""

from sklearn.model_selection import train_test_split

target = 'deposit'
X = df.drop(columns=[target])
y = df[target]

# 70/15/15 split via two steps — prevents leakage & keeps balance with stratify
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y, test_size=0.15, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val
)

print(len(X_train), len(X_val), len(X_test))
print(y_train.value_counts(normalize=True).round(3))
print(y_val.value_counts(normalize=True).round(3))
print(y_test.value_counts(normalize=True).round(3))

"""Pre-processing Pipeline"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer

num_cols = X_train.select_dtypes(include=['int64','float64']).columns.tolist()
cat_cols = X_train.select_dtypes(include=['object','category','bool']).columns.tolist()

numeric_pipe = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Handle OneHotEncoder API differences
try:
    categorical_pipe = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])
except TypeError:
    # fallback for older sklearn
    categorical_pipe = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
    ])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_pipe, num_cols),
        ('cat', categorical_pipe, cat_cols),
    ],
    remainder='drop'
)

"""Combine prep + model into one pipeline (baseline)"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score

clf = Pipeline(steps=[
    ('prep', preprocessor),
    ('model', LogisticRegression(max_iter=1000, class_weight='balanced'))
])

# Fit only on TRAIN
clf.fit(X_train, y_train)

# Validate
y_val_pred = clf.predict(X_val)
y_val_proba = clf.predict_proba(X_val)[:, 1] if hasattr(clf[-1], 'predict_proba') else None

print(classification_report(y_val, y_val_pred))
if y_val_proba is not None:
    print("ROC AUC (val):", roc_auc_score(y_val.map({'no':0,'yes':1}), y_val_proba))

"""# Data Resampling"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Load dataset
df = pd.read_csv("data_bank_marketing_campaign.csv")

# Target and features
target = 'deposit'
X = df.drop(columns=[target])
y = df[target]

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

"""Random Oversampling"""

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X_train, y_train)

print("Before:", y_train.value_counts())
print("After:", y_resampled.value_counts())

"""Random Oversampling"""

from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X_train, y_train)

print("Before:", y_train.value_counts())
print("After:", y_resampled.value_counts())

"""SMOTE (Synthetic Minority Over-sampling Technique)"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTENC
from imblearn.pipeline import Pipeline as ImbPipeline

# 1) split
df = pd.read_csv("data_bank_marketing_campaign.csv")
target = "deposit"
X = df.drop(columns=[target])
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 2) identify columns
num_cols = X_train.select_dtypes(include=["int64","float64"]).columns.tolist()
cat_cols = X_train.select_dtypes(include=["object","category","bool"]).columns.tolist()

# 3) first stage: impute numerics, ordinal-encode categoricals to integers
enc = ColumnTransformer([
    ("num", SimpleImputer(strategy="median"), num_cols),
    ("cat", Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("ord", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1))
    ]), cat_cols),
], remainder="drop")

# After enc, column order is [num..., cat...]
n_num = len(num_cols)
n_cat = len(cat_cols)
cat_indices = list(range(n_num, n_num + n_cat))

# 4) pipeline: encode -> SMOTENC -> model
pipe_smote = ImbPipeline(steps=[
    ("enc", enc),
    ("smote", SMOTENC(categorical_features=cat_indices, random_state=42)),
    ("model", LogisticRegression(max_iter=1000))
])

pipe_smote.fit(X_train, y_train)
print("OK: fitted with SMOTENC (categoricals ordinal-encoded first).")

"""Integrating into a pipeline"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTENC
from imblearn.pipeline import Pipeline as ImbPipeline

# If you already have X_train, y_train, skip to the column setup
df = pd.read_csv("data_bank_marketing_campaign.csv")
target = "deposit"
X = df.drop(columns=[target])
y = df[target]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

num_cols = X_train.select_dtypes(include=["int64","float64"]).columns.tolist()
cat_cols = X_train.select_dtypes(include=["object","category","bool"]).columns.tolist()

enc = ColumnTransformer([
    ("num", SimpleImputer(strategy="median"), num_cols),
    ("cat", Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("ord", OrdinalEncoder(
            handle_unknown="use_encoded_value",
            unknown_value=-1
        ))
    ]), cat_cols),
], remainder="drop")

# After 'enc', the transformed array is [num..., cat...]
n_num = len(num_cols)
cat_indices = list(range(n_num, n_num + len(cat_cols)))

pipe_smote = ImbPipeline(steps=[
    ("enc", enc),
    ("smote", SMOTENC(categorical_features=cat_indices, random_state=42)),
    ("model", LogisticRegression(max_iter=1000, class_weight="balanced"))
])

pipe_smote.fit(X_train, y_train)
print("Fitted with Ordinal‑encode + SMOTENC (categoricals handled).")

"""# Data Rescaling

## Preprocessing Block
"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer

num_cols = X_train.select_dtypes(include=["int64","float64"]).columns.tolist()
cat_cols = X_train.select_dtypes(include=["object","category","bool"]).columns.tolist()

numeric_pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# handle OneHotEncoder API diff: sparse_output (new) vs sparse (old)
try:
    categorical_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
    ])
except TypeError:
    categorical_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse=False))
    ])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_pipe, num_cols),
        ("cat", categorical_pipe, cat_cols),
    ],
    remainder="drop"
)

"""## Full Pipeline"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

clf = Pipeline(steps=[
    ("prep", preprocessor),
    ("model", LogisticRegression(max_iter=1000, class_weight="balanced"))
])

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

"""# Data Encoding"""

import pandas as pd

PATH = "data_bank_marketing_campaign.csv"  # adjust if needed
df = pd.read_csv(PATH)

# Standardize column names (common in your notebooks)
df.columns = (
    df.columns.str.strip()
              .str.lower()
              .str.replace(" ", "_")
              .str.replace(".", "", regex=False)
)

target = "deposit"               # yes/no in this dataset
X = df.drop(columns=[target])
y = df[target]

y = y.map({"no": 0, "yes": 1})   # now y is 0/1

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

"""## One-Hot Encoding"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer

num_cols = X_train.select_dtypes(include=["int64","float64"]).columns.tolist()
cat_cols = X_train.select_dtypes(include=["object","category","bool"]).columns.tolist()

numeric_pipe = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())   # optional for trees; helpful for linear/SVM/kNN
])

# Handle scikit-learn version differences: sparse_output (new) vs sparse (old)
try:
    categorical_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
    ])
except TypeError:
    categorical_pipe = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse=False))
    ])

preprocessor_ohe = ColumnTransformer(
    transformers=[
        ("num", numeric_pipe, num_cols),
        ("cat", categorical_pipe, cat_cols),
    ],
    remainder="drop"
)

# Fit on TRAIN only, then transform
preprocessor_ohe.fit(X_train)
X_train_enc = preprocessor_ohe.transform(X_train)
X_test_enc  = preprocessor_ohe.transform(X_test)

print(X_train_enc.shape, X_test_enc.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

clf_ohe = Pipeline(steps=[
    ("prep", preprocessor_ohe),
    ("model", LogisticRegression(max_iter=1000, class_weight="balanced"))
])

clf_ohe.fit(X_train, y_train)
print(classification_report(y_test, clf_ohe.predict(X_test)))

"""# Modelling

## Preparation
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

num_cols = X_train.select_dtypes(include=["int64","float64"]).columns.tolist()
cat_cols = X_train.select_dtypes(include=["object","category","bool"]).columns.tolist()

numeric_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())        # helpful for linear/SVM/kNN; harmless for trees
])

# handle sklearn version differences: sparse_output (new) vs sparse (old)
try:
    categorical_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
    ])
except TypeError:
    categorical_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse=False))
    ])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_pipe, num_cols),
        ("cat", categorical_pipe, cat_cols),
    ],
    remainder="drop"
)

"""## Train Baseline Models"""

candidates = {
    "LogReg": LogisticRegression(max_iter=1000, class_weight="balanced"),
    "DecisionTree": DecisionTreeClassifier(class_weight="balanced", random_state=42),
    "RandomForest": RandomForestClassifier(n_estimators=300, class_weight="balanced", random_state=42),
    "GradientBoosting": GradientBoostingClassifier(random_state=42),
}

results = []
for name, model in candidates.items():
    pipe = Pipeline([("prep", preprocessor), ("model", model)])
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    results.append((name, recall_score(y_test, y_pred)))

import pandas as pd
pd.DataFrame(results, columns=["Model","Recall"]).sort_values("Recall", ascending=False)

"""## Cross Validation Tuning"""

# Train/test split
df = df.copy()  # use your already-loaded dataframe
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

target = 'deposit' if 'deposit' in df.columns else 'y'
df[target] = df[target].map({'yes': 1, 'no': 0}).astype(int)

X = df.drop(columns=[target])
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Preprocess: one‑hot encode categoricals
cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()
num_cols = X_train.columns.difference(cat_cols).tolist()

preprocess = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),
        ('num', 'passthrough', num_cols),
    ]
)

# 3 Model pipeline
rf_pipe = Pipeline(steps=[
    ('prep', preprocess),
    ('clf', RandomForestClassifier(
        n_estimators=300, random_state=42, n_jobs=-1, class_weight='balanced_subsample'
    ))
])

rf_pipe.fit(X_train, y_train)

# 5 Get calibrated probabilities & pick threshold by target recall ----
proba = rf_pipe.predict_proba(X_test)[:, 1]
prec, rec, thr = precision_recall_curve(y_test, proba)

target_recall = 0.80
idxs = np.where(rec >= target_recall)[0]
best_threshold = thr[idxs[0]-1] if len(idxs) and idxs[0] > 0 else 0.0

y_pred_thr = (proba >= best_threshold).astype(int)
print("Chosen threshold:", round(best_threshold, 3))
print("Recall:", round(recall_score(y_test, y_pred_thr), 3),
      "| Precision:", round(precision_score(y_test, y_pred_thr), 3))

"""# Hyperparameter Tuning"""

Define a small param grid
param_grid = {
    "n_estimators":   [150, 300],
    "max_depth":      [None, 12],
    "min_samples_split": [2, 5],
    "min_samples_leaf":  [1, 2],
    "max_features":   ["sqrt"]
}

# helper: build model for given params
def make_pipeline(params):
    rf = RandomForestClassifier(
        random_state=42,
        class_weight="balanced",
        n_estimators=params["n_estimators"],
        max_depth=params["max_depth"],
        min_samples_split=params["min_samples_split"],
        min_samples_leaf=params["min_samples_leaf"],
        max_features=params["max_features"],
        n_jobs=-1
    )
    return Pipeline([("prep", preprocessor), ("clf", rf)])


# 5) Manual search loop (CV=3)
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
recall_scorer = make_scorer(recall_score, pos_label=1)

best_score = -np.inf
best_params = None

# iterate over the Cartesian product of small grid
keys, values = zip(*param_grid.items())
for combo in itertools.product(*values):
    params = dict(zip(keys, combo))
    pipe = make_pipeline(params)
    # fast CV with recall
    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=recall_scorer, n_jobs=-1)
    mean_recall = scores.mean()
    print(f"Params={params} | CV recall={mean_recall:.3f}")

    if mean_recall > best_score:
        best_score = mean_recall
        best_params = params

print("\n[RESULT] Best params:", best_params)
print(f"[RESULT] Best CV recall: {best_score:.3f}")


# 6) Fit best model + test eval
best_pipe = make_pipeline(best_params)
best_pipe.fit(X_train, y_train)

y_pred = best_pipe.predict(X_test)
print(f"[TEST] Recall @0.5: {recall_score(y_test, y_pred):.3f}")
print("[TEST] Confusion matrix:\n", confusion_matrix(y_test, y_pred))
print("[TEST] Classification report:\n", classification_report(y_test, y_pred, digits=3))


# 7) Optional: push recall higher
#    by lowering threshold (0.3)
if hasattr(best_pipe.named_steps["clf"], "predict_proba"):
    proba = best_pipe.predict_proba(X_test)[:, 1]
    thr = 0.30
    y_thr = (proba >= thr).astype(int)
    print(f"[THRESH] Recall @{thr:.2f}: {recall_score(y_test, y_thr):.3f}")
    print("[THRESH] Confusion matrix:\n", confusion_matrix(y_test, y_thr))

"""Hyperparameter Tuning Results (Random Forest)

- **Best Parameters:**  
  n_estimators=150, max_depth=None, min_samples_split=5, min_samples_leaf=1, max_features='sqrt'

- **Cross-validation Recall:** 0.652

- **Test Results @ Threshold = 0.5**  
  - Recall: 0.653  
  - Precision (class=1): 0.722  
  - Accuracy: 0.714  
  - F1-score (class=1): 0.686  
  - Balanced but misses ~35% of customers.

- **Test Results @ Threshold = 0.3**  
  - Recall: 0.830  
  - Precision decreases (more false positives).  
  - Best choice if the business priority is **not missing actual customers**.

Lowering the threshold significantly improves recall (from ~65% → 83%), which is aligned with the business goal of maximizing customers capture.

# Final Model Intepretation
"""

# Load dataset
df = pd.read_csv("data_bank_marketing_campaign.csv")

# Detect target column
target_candidates = ["y","deposit","subscribed","subscription","target"]
target_col = next(c for c in target_candidates if c in df.columns)

# Map to binary 0/1
y = df[target_col].astype(str).str.strip().str.lower().map(
    {"yes":1,"y":1,"true":1,"1":1,"no":0,"n":0,"false":0,"0":0}
).astype(int)

X = df.drop(columns=[target_col])

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

"""## Pipeline"""

# Separate categorical/numerical
cat_cols = X_train.select_dtypes(include=["object","category","bool"]).columns
num_cols = [c for c in X_train.columns if c not in cat_cols]

# Preprocessor
preprocessor = ColumnTransformer([
    ("cat", Pipeline([
        ("imp", SimpleImputer(strategy="most_frequent")),
        ("ohe", OneHotEncoder(handle_unknown="ignore"))
    ]), cat_cols),
    ("num", Pipeline([
        ("imp", SimpleImputer(strategy="median"))
    ]), num_cols)
])

# Final pipeline
final_pipe = Pipeline([
    ("preprocessor", preprocessor),
    ("clf", RandomForestClassifier(
        random_state=42,
        class_weight="balanced",
        n_estimators=300,
        max_features="sqrt"
    ))
])

# Fit
final_pipe.fit(X_train, y_train)

"""## Feature Importance"""

import numpy as np

# 1) Importances
feat_imp = final_pipe.named_steps["clf"].feature_importances_

# 2) Feature names after encoding
prep = final_pipe.named_steps["preprocessor"]
try:
    features = prep.get_feature_names_out().tolist()
except Exception:
    # fallback if get_feature_names_out not available
    features = []
    for name, trans, cols in prep.transformers_:
        if trans in ("drop", None): continue
        if hasattr(trans, "get_feature_names_out"):
            features += trans.get_feature_names_out(cols).tolist()
        else:
            features += list(cols)

# 3) Tidy DataFrame
df_feat_imp = (
    pd.DataFrame({"feature": features, "importance": feat_imp})
      .sort_values("importance", ascending=False)
      .reset_index(drop=True)
)

print(df_feat_imp.head(20))

"""## Feature Importances Pipeline"""

# Rebuild Final Pipeline
def _build_df_feat_imp_from_pipeline(final_pipe, X_sample: pd.DataFrame) -> pd.DataFrame:
    clf = final_pipe.named_steps["clf"]
    prep = final_pipe.named_steps["preprocessor"]
    importances = clf.feature_importances_

    # Get encoded feature names (robust)
    try:
        names = prep.get_feature_names_out().tolist()
    except Exception:
        names = []
        for name, trans, cols in prep.transformers_:
            if trans in ("drop", None) or name == "remainder":
                continue
            inner = trans
            if hasattr(trans, "steps"):
                inner = trans.steps[-1][1]
            if hasattr(inner, "get_feature_names_out"):
                try:
                    names.extend(inner.get_feature_names_out(cols).tolist())
                    continue
                except Exception:
                    pass
            # Fallback: generic names by width
            try:
                width = prep.transform(X_sample[cols].head(5)).shape[1]
            except Exception:
                width = len(cols)
            base = str(cols[0]) if len(cols)==1 else name
            names.extend([f"{base}__{i}" for i in range(width)])

    m = min(len(names), len(importances))
    return (pd.DataFrame({"feature": names[:m], "importance": importances[:m]})
              .sort_values("importance", ascending=False)
              .reset_index(drop=True))

if "df_feat_imp" not in globals():
    # Try to use X_test if available; else X_train
    _X_sample = globals().get("X_test", globals().get("X_train", None))
    if _X_sample is None:
        raise NameError("Need X_test or X_train in scope to derive encoded feature names.")
    df_feat_imp = _build_df_feat_imp_from_pipeline(final_pipe, _X_sample)

# 2) Pick top-k features
top_k = 20  # adjust as needed
top_imp = df_feat_imp.head(top_k).copy()
# for Seaborn/matplotlib ordering, sort ascending so biggest appears at top of barh
top_imp = top_imp.iloc[::-1]  # reverse to plot largest on top in barh

# 3) Plot
plt.figure(figsize=(8, 6))
if _HAS_SNS:
    sns.barplot(data=top_imp, x="importance", y="feature")
else:
    # Pure Matplotlib fallback
    plt.barh(top_imp["feature"], top_imp["importance"])

plt.xlabel("Importance")
plt.ylabel("Encoded Feature")
plt.title(f"Top {top_k} Feature Importances (Random Forest)")
plt.tight_layout()
plt.show()

"""## Profit Estimation"""

# Predict on test set
y_pred = final_pipe.predict(X_test)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Heatmap
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Pred 0","Pred 1"],
            yticklabels=["True 0","True 1"])
plt.title("Confusion Matrix (Final RF Model)")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

plt.figure(figsize=(5,4))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap='Blues',
            xticklabels=["Pred 0","Pred 1"],
            yticklabels=["True 0","True 1"])
plt.title("Normalized Confusion Matrix (Final RF Model)")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

"""**Analysis**

**Profit Drivers**

- True Positives (477) represent customers who were targeted
- True Negatives (639) reduce unnecessary contact

**Cost Factors**

- False Positives (177) add marketing expense without returns.
- False Negatives (270) represent missed potential profit, since willing customers were not contacted.


- Model captures 64% of actual customers(good recall), but still misses 36% → opportunity cost.
- Precision trade-off: more aggressive targeting could increase recall but raise costs from false positives.

# Conclusion and Recommendation

## Conclusion

**Best Model:**
The best performing model for this dataset is the Random Forest model.

**Best Hyperparameters:**
- n_estimators = 150
- max_depth = None
- min_samples_split = 5
- min_samples_leaf = 1
- max_features = 'sqrt'

**Model Performance:**
- Accuracy: ~71.4% on the test set
- Recall (threshold=0.5): ~65.3%
- Recall (threshold=0.3): ~83.0% (preferred for business objective to capture more customers)

By using machine learning, the model can automatically identify potential customers that will put deposit in the bank. Compared to a manual or random targeting approach, this increases efficiency by focusing on potential depositors, reduce risk of profit loss and maximizing revenue for the bank.

## Recommendation for Model

**Model Limitations:**
- Good recall, but precision drops when recall is maximized (more false positives).
- Accuracy (~71%) indicates room for improvement.
- Model may not capture some expected relationship or correlations due to limited features.

**Future Improvements:**
- add domain-specific features (e.g., transactions, engagement)
- Explore other models and do tests.
- Add track performance to make sure the deposit follows the target.

## Recommendation for Business

- Focus campaigns on customers with higher education because they are most likely to put deposit to the bank.
- Target past customers with good reputation on the bank to put their deposit.
- Categorize customers by job type and age group to adapt the marketing campaign with the targetted audience.
- Offer premium products to customers with higher balances, and beginner level deposits.
- Concentrate marketing efforts in months with historically high success rates
"""